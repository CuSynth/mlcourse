{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим задачу бинарной классификации: $\\{X_i, Y_i\\}$, где $y_i$ могут принимать только значения из множества {0, 1}. Хотим предсказывать, с какой вероятностью ($p_i$) объект $x_i$ принадлежит тому или иному классу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим отношение шансов: \n",
    "$$ odds_i = \\frac{p_i}{1-p_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте прологарифмируем, получим величину от $-inf$ до $+inf$\n",
    "$$logit(p_i) = \\eta_i = ln(\\frac{p_i}{1-p_i})$$\n",
    "А полученную функцию будем называть логистическим преобразорванием.\n",
    "Тогда:\n",
    "$$ln(\\frac{p_i}{1-p_i}) = x_i*{\\theta}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуя, получим:\n",
    "$$\\Large p_i = \\frac{1.}{(1+e^{-x_i*{\\theta}})} = \\sigma(x_i*{\\theta}) = sigmoid(x_i*{\\theta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда вероятности: \\\n",
    "$p_{+} = \\sigma(x*\\theta)$\n",
    "\n",
    "$p_{-} = 1 - \\sigma(x*\\theta) = \\sigma(-x*\\theta)$\n",
    "\n",
    "$P(y=y_{i}|x_{i}, \\theta) = \\sigma(M)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь $M$ - отступ:\n",
    "$$\\Large M(x_i) = M_i = y_i * (<w, x_i> - b)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод максимального правдоподобия (максимизируем вероятность получить $\\vec{y}$ на выборке $X$):\n",
    "$$P\\left(\\vec{y} \\mid X, \\vec{w}\\right) = \\prod_{i=1}^{\\ell} P\\left(y = y_i \\mid \\vec{x_i}, \\vec{w}\\right)$$\n",
    "\n",
    "$\\ell$ - длина выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взяв log:\n",
    "$$\\Large \\log P\\left(\\vec{y} \\mid X, \\vec{w}\\right) = \\dots =  - \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> необходимо минимизировать:\n",
    "$$ \\mathcal{L_{log}} = \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}}) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$L_2$ reg:\n",
    "$$\\large L_2(X, \\vec{y}, \\vec{w}) = \\mathcal{L_{log}} (X, \\vec{y}, \\vec{w}) + \\lambda |\\vec{w}|^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда, введя $C=\\frac{1}{\\lambda}$:\n",
    "$$\\large \\hat{w} = \\arg \\min_{\\vec{w}} L_2(X, \\vec{y}, \\vec{w}) = \\arg \\min_{\\vec{w}}\\ (C\\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}})+ |\\vec{w}|^2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!\n",
    "<!-- <img src=\"BCE.png\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В бинарном линейно разделимом случае ищем разделяющую гиперплоскость, расстояние от которой до каждого класса минимально.\n",
    "Предсказания:\n",
    "$$\\Large\\alpha(x, \\theta, \\theta_0) = sign(<x, \\theta> - \\theta_0)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Введем отступ:\n",
    "$$\\Large M(x_i) = M_i = y_i * (<w, x_i> - b)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функционал эмпирического риска:\n",
    "$$\\Large Q(w, b, X) = \\sum_{i = 1}^{N}[M_i < 0]$$\n",
    "$$\\Large Q\\rightarrow min$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сведем к задаче минимизации эмпирического риска:\n",
    "\n",
    "$$\\Large [M_i < 0]\\leq L(M_i)$$\n",
    "\n",
    "\n",
    "где $L:\\R\\rightarrow\\R_+$ - непрерывная неубывающая функция."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда:\n",
    "$$\\Large \\sum_{i = 1}^{N}L(M_i)\\rightarrow min$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взяв $L = (1 - M)_+$ - получим метод опорных векторов(Support Vector Machine) \\\n",
    "Взяв $L = log(1 + e^{-M})$ получим лог. регрессию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SVM.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полоса: \\\n",
    "$-1\\leq(<x_i, \\theta>+b)\\leq 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмем 2 объекта на границе полосы (опорные вектора):\n",
    "$$b - 1 + <x_+, \\theta> = 0$$\n",
    "$$b + 1 + <x_-, \\theta> = 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"SVMpm.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$<(x_+-x_-), \\frac{\\theta}{\\lVert{\\theta}\\rVert}> = \\frac{2}{\\lVert{\\theta}\\rVert}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда:\n",
    "\n",
    "$\\begin{equation}\n",
    " \\begin{cases}\n",
    "  0.5<\\theta, \\theta>\\rightarrow min\n",
    "  \\\\\n",
    "  y_i(<x_i, \\theta>+b)\\geq 1\n",
    " \\end{cases}\n",
    "\\end{equation}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теорема Куна-Такера =>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{equation}\n",
    " \\begin{cases}\n",
    "   L(\\theta, b) = 0.5<\\theta, \\theta> - \\sum_i \\lambda_i({y_i(<x_i, \\theta>+b)-1})\\rightarrow min_{\\theta, b}, max_{\\lambda_i}\n",
    "   \\\\\n",
    "   \\lambda_i \\geq 0\n",
    "   \\\\\n",
    "   \\lambda_i (y_i(<x_i, \\theta>+b)-1) = 0\n",
    " \\end{cases}\n",
    "\\end{equation}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ищем производные \n",
    "$$\\frac{\\partial{L}}{\\partial\\theta_j} = 0 = \\theta_j - \\sum_i \\lambda_iy_ix_{ij}$$\n",
    "$$\\frac{\\partial{L}}{\\partial{b}} = 0 = \\sum_i \\lambda_iy_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подставляем:\n",
    "$$L = \\sum_i \\lambda_i - 0.5<\\sum_i \\lambda_iy_ix_{i}, \\sum_j \\lambda_jy_jx_{j}>$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оптимизируем градиентным спуском."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим ошибку для линейно неразделимого случая:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"sgd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку используя предикаты. \\\n",
    "Рассмотрим энтропию:\n",
    "$$S = -\\sum_{i = 1}^{C}p_i log_2 p_i$$\n",
    "Это математическое ожидание количества бит, которым необходимо закодировать сообщение/мера порядка (чем выше, тем менее упорядочена выборка)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делим выборку и пытаемся сделать энтропию ниже в выборках после разделения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прирост информации (information gain):\n",
    "$$IG(P) = S_0 - \\sum_{i = 1}^{2}\\frac{N_i}{N}S_i$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбираем предикат так, что $IG\\rightarrow max$:\n",
    "$$argmax_P(IG(\\phi))$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функционал качества:\n",
    "$$Q(N) = H(N) - \\frac{N_{1}}{N}*H(N_1) - \\frac{N_{2}}{N}*H(N_2)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой критерий качества разбиения - неопределенность Джини (Gini impurity):\n",
    "$$ G = \\sum_{k=1}^{C} p_k*(1 - p_k) $$ \n",
    "\n",
    "(вероятность проклассифицировать неправильным образом случайно взятую точку из нашего датасета)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Останавливаемся при достижении определенной точности/глубины/количества элементов в листе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для {n = 1, ..., N} генерируем выборку $\\tilde X_n$ с помощью бутстрэпа. Строим над ней дерево $b_n$ (разбиения в вершинах - по подмножеству признаков). \\\n",
    "Предсказание: возвращааем результат голосования/среднее значение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По т. Байеса:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(y|x_1, x_2, ...x_M) = \\frac{P(y)P(x_1, x_2, ...x_M|c)}{P(x_1, x_2, ...x_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагая независимость признаков:\n",
    "$$P(y)P(x_1, x_2, ...x_M|y) = P(y)P(x_1|y)P(x_2|y)...P(x_M|y) = P(y)\\prod_{i = 1}^{M}P(x_i|y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда:\n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i \\mid y)}\n",
    "                                 {P(x_1, \\dots, x_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как $P(x_1, \\dots, x_n) = const$, то:\n",
    "$$P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тогда алгоритм:\n",
    "$$\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идея линейного классификатора: признаковое пространство может быть разделено гиперплоскостью на два полупространства, в каждом из которых прогнозируется одно из двух значений целевого класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Линейная регресия - модель вида \n",
    "$$\\Large \\^y = <w, x> + w_0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем метрики: <br>\n",
    "$MAE = \\frac{1}{N}\\sum_{i=1}^{N}\\big|a(x_i) - y_i\\big|$ - абсолютная ошибка.<br>\n",
    "$𝑀𝑆𝐸 = \\frac{1}{N}\\sum_{i=1}^{N}\\big(a(x_i) - y_i\\big)^2$ - квадратичная ошибка.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Точное значение для w в MSE:\n",
    "$$\\Large w = (X^TX)^{-1}X^TY$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "!\n",
    "<!-- <img src=\"grad.png\"> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Но линейная регрессия дает значения $(-\\inf; \\inf)$. Хотим вероятность предсказания класса 1.\n",
    "=> используем формула лог. регрессии:\n",
    "$$ \\Large P_{+} = \\frac{1}{1 + e^{-\\^y}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "При этом:\n",
    "$$\\Large P_+(x_i) = P(y_i = +1 | x_i, w) = \\sigma(<w, x>)$$\n",
    "$$\\Large P_-(x_i) = P(y_i = -1 | x_i, w) = \\sigma(-<w, x>)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяя:\n",
    "$$\\Large P(y=y_i|x_i, w) = \\sigma(y_i<w,x_i>)=\\sigma(M)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Правдоподобие:\n",
    "$$\\large P\\left(\\vec{y} \\mid X, \\vec{w}\\right) = \\prod_{i=1}^{\\ell} P\\left(y = y_i \\mid \\vec{x_i}, \\vec{w}\\right)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем log для перехода к сумме:\n",
    "$$\\large \\begin{array}{rcl} \\log P\\left(\\vec{y} \\mid X, \\vec{w}\\right) =\\dots= - \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}\\vec{x_i}}) \\end{array}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Максимизация правдоподобия дает минимизацию выражения:\n",
    "$$\\large \\mathcal{L} (X, \\vec{y}, \\vec{w}) = \\sum_{i=1}^{\\ell} \\log (1 + \\exp^{-y_i\\vec{w}^T\\vec{x_i}}).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для M классов:\n",
    "$$\\Large\\^{\\overrightarrow{y}} = softmax(W*\\overrightarrow{x})$$\n",
    "$$\\Large softmax(\\overrightarrow{z}) = {\\frac{e^{z_i}}{\\sum_{i=1}^{M}e^{z_i}}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вероятности:\n",
    "$$\\Large\\^{\\overrightarrow{y}} \\in \\R^M,\\ \\sum_{i = 1}^{M}\\^{y}_i = 1 $$\n",
    "$$\\Large\\^y = argmax(\\^{\\overrightarrow{y}})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
